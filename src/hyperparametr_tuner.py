from datetime import datetime
import os
from catboost import CatBoostClassifier
import joblib
from lightgbm import LGBMClassifier
from sklearn.model_selection import cross_val_score
from xgboost import XGBClassifier
import optuna
from model_manager import ModelManager

class HyperparametrTuner:
    """
    –ö–ª–∞—Å—Å, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø–æ–¥–æ–±—Ä–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é **optuna**.
    """
    def __init__(self, X_train, y_train, params_config, 
                 n_trials=30, cv=5, random_state=42, scoring='roc_auc', direction='maximize'):
        """
        - **X_train**: train –≤—ã–±–æ—Ä–∫–∞;
        - **y_train**: —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤;
        - **params_config**: —Å–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;
        - **n_trials(default=30)**: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤;
        - **cv(default=5)**: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤;
        - **random_state(default=42)**: —Å–∏–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª;
        - **scoring(default='roc_auc')**: –º–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å;
        - **direction(default='maximize')**: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        self.X_train = X_train
        self.y_train = y_train
        self.params_config = params_config
        self.n_trials = n_trials
        self.cv = cv
        self.random_state = random_state
        self.scoring = scoring
        self.direction = direction
        self.best_params = {}
        self.results = {}
        self.model_manager = ModelManager()

        self.model_classes = {
            'CatBoostClassifier': CatBoostClassifier,
            'LGBMClassifier': LGBMClassifier,
            'XGBClassifier': XGBClassifier
        }

    def gererate_objective(self, model_name, model_config):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ objective –¥–ª—è **optuna**.

        ### Agrumetns:
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏
            model_config: —Å–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

        **return**: —Ñ—É–Ω–∫—Ü–∏—é objective –¥–ª—è **optuna**
        """
        model_class = self.model_classes[model_config['class']]
        grid_params = model_config['grid_params']
        fixed_params = model_config['fixed_params']

        def objective(trial):
            params = {}
            for param_name, param_config in grid_params.items():
                if param_config['type'] == 'categorical':
                    params[param_name] = trial.suggest_categorical(
                        param_name, param_config['values']
                    )
                elif param_config['type'] == 'int':
                    params[param_name] = trial.suggest_int(
                        param_name, 
                        param_config['low'], 
                        param_config['high'],
                        log=param_config.get('log', False)
                    )
                elif param_config['type'] == 'float':
                    params[param_name] = trial.suggest_float(
                        param_name,
                        param_config['low'],
                        param_config['high'],
                        log=param_config.get('log', False),
                        step=param_config.get('step', None)
                    )

            params.update(fixed_params)

            model = model_class(**params)

            scores = cross_val_score(
                model, self.X_train, self.y_train, 
                scoring=self.scoring, cv=self.cv, n_jobs=-1
            )

            return scores.mean()
        
        return objective
    
    def tune_models(self, models_to_tune=None):
        """
        –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é **optuna**
        """
        if models_to_tune is None:
            models_to_tune = list(self.params_config.keys())

        print(f"üéØ –ó–∞–ø—É—Å–∫ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è: {models_to_tune}")

        for model_name in models_to_tune:
            print(f"\nüîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {model_name}...")
            objective = self.gererate_objective(model_name, self.params_config[model_name])
            
            study = optuna.create_study(
                direction=self.direction,
                sampler=optuna.samplers.TPESampler(seed=42)
            )

            study.optimize(objective, n_trials=self.n_trials)
            self.best_params[model_name] = study.best_params
            self.results[model_name] = study

            print(f"‚úÖ {model_name}: –ª—É—á—à–∏–π {self.scoring} = {study.best_value:.4f}")
            print(f"   –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")

        return self.best_params
    
    def get_tuned_models(self):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        tuned_models = {}
        
        for model_name, best_params in self.best_params.items():
            model_config = self.params_config[model_name]
            model_class = self.model_classes[model_config['class']]
            
            all_params = {**best_params, **model_config['fixed_params']}
            
            tuned_models[f"{model_name}_tuned"] = model_class(**all_params)
        
        return tuned_models

    def get_study_analysis(self, model_name):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        if model_name in self.results:
            return self.results[model_name]
        else:
            print(f"Study –¥–ª—è {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
    def save_tuning_results(self, study_name="hyperparameter_tuning"):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{study_name}_{timestamp}.pkl"
        filepath = os.path.join(self.model_manager.models_dir, filename)
        
        results = {
            'best_params': self.best_params,
            'study_results': self.results,
            'config_used': self.params_config,
            'timestamp': timestamp
        }
        
        joblib.dump(results, filepath)
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—é–Ω–∏–Ω–≥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
        return filepath
    
    def load_tuning_results(self, filepath):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—é–Ω–∏–Ω–≥–∞
        """
        results = joblib.load(filepath)
        self.best_params = results['best_params']
        self.results = results['study_results']
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—é–Ω–∏–Ω–≥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑: {filepath}")
        return results
